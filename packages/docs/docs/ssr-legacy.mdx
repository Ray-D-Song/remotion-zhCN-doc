---
image: /generated/articles-docs-ssr-legacy.png
id: ssr-legacy
title: 服务器端渲染（v1 和 v2）
crumb: "传统文档"
---

:::info
这份文档介绍了 Remotion v1 和 Remotion v2 中的服务器端渲染工作原理。要查看 [3.0 及以上版本的渲染，请点击这里。](/docs/ssr)
:::

Remotion 的渲染引擎建立在 Node.JS 上，这使得在云端渲染视频变得异常简单。

由于 Remotion 是使用跨平台技术（_Node.JS、FFMPEG、Puppeteer_）构建的，您可以轻松在基于 Linux 的系统上运行它，甚至可以将您的视频容器化。

在这个页面上，我们展示了 Remotion 在模板中内置的示例，展示了其服务器端渲染功能 [（内置于模板中）](/docs/ssr)！

## 以编程方式渲染视频

NPM 包 `@remotion/renderer` 为您提供了一个用于以编程方式渲染视频的 API。您可以通过三个步骤制作视频：创建一个 Webpack bundle，渲染帧，并将它们拼接成 MP4。这使您更加独立，例如，允许您跳过拼接过程，如果您只想要一个 PNG 序列。

按照下面的示例来查看如何渲染视频：

```tsx
import { bundle } from "@remotion/bundler";
import {
  getCompositions,
  renderFrames,
  stitchFramesToVideo,
} from "@remotion/renderer";
import fs from "fs";
import os from "os";
import path from "path";

const start = async () => {
  // The composition you want to render
  const compositionId = "HelloWorld";

  // Create a webpack bundle of the entry file.
  const bundleLocation = await bundle(require.resolve("./src/index.ts"));

  // Extract all the compositions you have defined in your project
  // from the webpack bundle.
  const comps = await getCompositions(bundleLocation, {
    // You can pass custom input props that you can retrieve using getInputProps()
    // in the composition list. Use this if you want to dynamically set the duration or
    // dimensions of the video.
    inputProps: {
      custom: "data",
    },
  });

  // Select the composition you want to render.
  const composition = comps.find((c) => c.id === compositionId);

  // Ensure the composition exists
  if (!composition) {
    throw new Error(`No composition with the ID ${compositionId} found`);
  }

  // We create a temporary directory for storing the frames
  const framesDir = await fs.promises.mkdtemp(
    path.join(os.tmpdir(), "remotion-"),
  );

  // We create JPEGs for all frames
  const { assetsInfo } = await renderFrames({
    config: composition,
    // Path of the webpack bundle you have created
    bundle: bundleLocation,
    // Get's called after bundling is finished and the
    // actual rendering starts.
    onStart: () => console.log("Rendering frames..."),
    onFrameUpdate: (f) => {
      // Log a message whenever 10 frames have rendered.
      if (f % 10 === 0) {
        console.log(`Rendered frame ${f}`);
      }
    },
    // How many CPU threads to use. `null` will use a sane default (half of the available threads)
    // See 'CLI options' section for concurrency options.
    parallelism: null,
    outputDir: framesDir,
    // React props passed to the root component of the sequence. Will be merged with the `defaultProps` of a composition.
    inputProps: {
      titleText: "Hello World",
    },
    // Can be either 'jpeg' or 'png'. JPEG is faster, but has no transparency.
    imageFormat: "jpeg",
  });

  // Add this step if you want to make an MP4 out of the rendered frames.
  await stitchFramesToVideo({
    // Input directory of the frames
    dir: framesDir,
    // Overwrite existing video
    force: true,
    // Possible overwrite of video metadata,
    // we suggest to just fill in the data from the
    // video variable
    fps: composition.fps,
    height: composition.height,
    width: composition.width,
    // Must match the value above for the image format
    imageFormat: "jpeg",
    // Pass in the desired output path of the video. Et voilà!
    outputLocation: path.join(framesDir, "out.mp4"),
    // FFMPEG pixel format
    pixelFormat: "yuv420p",
    // Information needed to construct audio correctly.
    assetsInfo,
    webpackBundle: bundleLocation,
    // Hook into the FFMPEG progress
    onProgress: (frame) => undefined,
  });
};

start();
```

## API 参考

- [bundle()](/docs/bundle)
- [getCompositions()](/docs/renderer/get-compositions)
- [renderMedia()](/docs/renderer/render-media)
- [stitchFramesToVideo()](/docs/renderer/stitch-frames-to-video)

