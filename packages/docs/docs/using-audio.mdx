---
image: /generated/articles-docs-using-audio.png
title: 使用音频
sidebar_label: 音频
id: using-audio
crumb: "Techniques"
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## 导入音频

[将音频文件放入 `public/` 文件夹](/docs/assets) 并使用 [`staticFile()`](/docs/staticfile) 来引用它。  
在组件中添加一个 [`<Audio/>`](/docs/audio) 标签来为其添加声音。

```tsx twoslash
import { AbsoluteFill, Audio, staticFile } from "remotion";

export const MyComposition = () => {
  return (
    <AbsoluteFill>
      <Audio src={staticFile("audio.mp3")} />
    </AbsoluteFill>
  );
};
```

您也可以通过传递 URL 来添加远程音频：

```tsx twoslash
import { AbsoluteFill, Audio } from "remotion";

export const MyComposition = () => {
  return (
    <AbsoluteFill>
      <Audio src="https://example.com/audio.mp3" />
    </AbsoluteFill>
  );
};
```

默认情况下，音频将从开头播放，音量和长度都为最大值。
您可以通过添加更多的音频标签来混合多个音轨。

## 剪切或修剪音频

`<Audio />` 标签支持 `startFrom` 和 `endAt` 属性。在下面的示例中，我们假设合成的 [`fps`](/docs/composition#fps) 为 `30`。

```tsx twoslash {6}
import { AbsoluteFill, Audio, staticFile } from "remotion";

export const MyComposition = () => {
  return (
    <AbsoluteFill>
      <Audio src={staticFile("audio.mp3")} startFrom={60} endAt={120} />
    </AbsoluteFill>
  );
};
```

通过传递 `startFrom={60}`，播放将立即开始，但会裁剪掉音频的前 2 秒。  
通过传递 `endAt={120}`，文件中第 4 秒后的任何音频都将被裁剪掉。

音频将播放从 `00:02:00` 到 `00:04:00` 的范围，意味着音频将播放 2 秒。

## 延迟音频

使用带有正值 `from` 的 `<Sequence>` 来延迟音频的播放。
在下面的示例中，音频将在 100 帧后开始播放（从开头）。

```tsx twoslash {6-8}
import { AbsoluteFill, Audio, Sequence, staticFile } from "remotion";

export const MyComposition = () => {
  return (
    <AbsoluteFill>
      <Sequence from={100}>
        <Audio src={staticFile("audio.mp3")} />
      </Sequence>
    </AbsoluteFill>
  );
};
```

## 控制音量

您可以使用 [`volume`](/docs/audio#volume) 属性来控制音量。

最简单的方法是传递一个介于 0 和 1 之间的数字。`1` 是最大音量，`0` 会静音音频。

```tsx twoslash {8}
import { Audio } from "remotion";
import audio from "./audio.mp3";

export const MyComposition = () => {
  return (
    <div>
      <div>Hello World!</div>
      <Audio src={audio} volume={0.5} />
    </div>
  );
};
```

您还可以通过传递一个接受帧数并返回音量的函数来随时间改变音量。

```tsx twoslash {8-10}
import { AbsoluteFill, Audio, interpolate, staticFile } from "remotion";

export const MyComposition = () => {
  return (
    <AbsoluteFill>
      <Audio
        src={staticFile("audio.mp3")}
        volume={(f) =>
          interpolate(f, [0, 30], [0, 1], { extrapolateLeft: "clamp" })
        }
      />
    </AbsoluteFill>
  );
};
```

在这个示例中，我们使用 [interpolate()](/docs/interpolate) 函数在 30 帧内淡入音频。请注意，由于不允许负值，我们需要设置 `extrapolateLeft: 'clamp'` 选项以确保没有负值。

在回调函数中，正在播放音频的第一个帧被标记为`0`，不管`useCurrentFrame()`的值是多少。

如果音量在变化，请优先使用回调函数。这将使 Remotion 能够在时间轴上绘制音量曲线，并且性能更好。

:::note
当使用[`<Player>`](/docs/player)时，请注意 Mobile Safari 不支持`volume`属性。音频混音可能无法按预期播放。
:::

## `muted` 属性

您可以传入`muted`，它可能会随时间变化。当`muted`为 true 时，音频将在那个时间被省略。在下面的示例中，我们在第 40 帧和第 60 帧之间将音轨静音。

```tsx twoslash {8}
import { AbsoluteFill, Audio, staticFile, useCurrentFrame } from "remotion";

export const MyComposition = () => {
  const frame = useCurrentFrame();

  return (
    <AbsoluteFill>
      <Audio src={staticFile("audio.mp3")} muted={frame >= 40 && frame <= 60} />
    </AbsoluteFill>
  );
};
```

## 使用 `<Video />` 标签中的音频

来自[`<Video />`](/docs/video)和[`<OffthreadVideo />`](/docs/offthreadvideo)标签中的音频也包含在输出中。您可以以相同的方式使用[`startFrom`, `endAt`](/docs/video/#startfrom)、[`volume`](/docs/video/#volume)和[`muted`](/docs/video/#muted)属性。

## 控制播放速度

<AvailableFrom v="2.2" />

您可以使用`playbackRate`属性来控制音频的速度。`1`是默认值，表示正常速度，`0.5`会减慢音频速度，使其变为原来的两倍长，`2`会加快音频速度，使其变为原来的两倍快。

虽然 Remotion 不限制可能的播放速度范围，在开发模式下使用[`HTMLMediaElement.playbackRate`](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/playbackRate) API，当播放速度低于`0.0625`或高于`16`时会抛出错误。在撰写本文时，Google Chrome 如果播放速度低于`0.0625`或高于`16`会抛出异常。

## 音频可视化

您可以获取音频数据并基于此创建可视化效果。有关更多信息，请参阅页面[音频可视化](/docs/audio-visualization)。

## 仅渲染音频

支持导出为 `mp3`、`aac` 和 `wav`：

<Tabs
defaultValue="cli"
values={[
{ label: 'CLI', value: 'cli', },
{ label: 'renderMedia()', value: 'node', },
{ label: 'Lambda', value: 'lambda', },
]
}>
<TabItem value="cli">

通过 CLI 仅渲染音频，导出时需指定扩展名：

```
npx remotion render src/index.ts my-comp out/audio.mp3
```

或者使用 `--codec` 标志自动选择一个良好的输出文件名：

```
npx remotion render src/index.ts my-comp --codec=mp3
```

  </TabItem>

  <TabItem value="node">

通过 Node.JS 仅渲染音频，使用 [`renderMedia()`](/docs/renderer/render-media) 并将 [`codec`](/docs/renderer/render-media#codec) 设置为音频编解码器。

```tsx twoslash
// @module: ESNext
// @target: ESNext
import { bundle } from "@remotion/bundler";
import { getCompositions, renderMedia } from "@remotion/renderer"; // The composition you want to render
import path from "path";
const compositionId = "HelloWorld";

// You only have to do this once, you can reuse the bundle.
const entry = "./src/index";
console.log("Creating a Webpack bundle of the video");
const bundleLocation = await bundle(path.resolve(entry), () => undefined, {
  // If you have a Webpack override, make sure to add it here
  webpackOverride: (config) => config,
});

// Parametrize the video by passing arbitrary props to your component.
const inputProps = {
  foo: "bar",
};

// Extract all the compositions you have defined in your project
// from the webpack bundle.
const comps = await getCompositions(bundleLocation, {
  // You can pass custom input props that you can retrieve using getInputProps()
  // in the composition list. Use this if you want to dynamically set the duration or
  // dimensions of the video.
  inputProps,
});

// Select the composition you want to render.
const composition = comps.find((c) => c.id === compositionId);

// Ensure the composition exists
if (!composition) {
  throw new Error(`No composition with the ID ${compositionId} found.
  Review "${entry}" for the correct ID.`);
}
const outputLocation = `out/${compositionId}.mp4`;

// ---cut---
await renderMedia({
  composition,
  serveUrl: bundleLocation,
  codec: "mp3",
  outputLocation,
  inputProps,
});
```

  </TabItem>
    <TabItem value="lambda">

通过 Lambda 仅渲染音频，使用 [`renderMediaOnLambda()`](/docs/lambda/rendermediaonlambda) 并将 [`codec`](/docs/lambda/rendermediaonlambda#codec) 设置为音频编解码器，将 [`imageFormat`](/docs/lambda/rendermediaonlambda#imageformat) 设置为 `none`。

```tsx twoslash
// @module: esnext
// @target: es2017
import { renderMediaOnLambda } from "@remotion/lambda";
// ---cut---

const { bucketName, renderId } = await renderMediaOnLambda({
  region: "us-east-1",
  functionName: "remotion-render-bds9aab",
  composition: "MyVideo",
  framesPerLambda: 20,
  serveUrl:
    "https://remotionlambda-qg35eyp1s1.s3.eu-central-1.amazonaws.com/sites/bf2jrbfkw",
  inputProps: {},
  codec: "mp3",
  imageFormat: "none",
  maxRetries: 1,
  privacy: "public",
});
```

通过 Lambda CLI 渲染，使用 [`npx remotion lambda render`](/docs/lambda/cli/render) 命令并传递 [`--codec`](/docs/lambda/cli/render#--codec) 标志：

```
npx remotion lambda render --codec=mp3 https://remotionlambda-qg35eyp1s1.s3.eu-central-1.amazonaws.com/sites/bf2jrbfkw my-comp
```

  </TabItem>
</Tabs>

## 操作顺序<AvailableFrom v="4.0.141"/>

在 Remotion v4.0.141 之前，未定义音频操作的应用顺序，预览和渲染中的行为可能有所不同。

自 Remotion v4.0.141 起，操作顺序保证如下：

1. 裁剪音频（使用 [`startFrom`](/docs/audio#startfrom--endat)）。
2. 偏移音频（将其放入 [序列](/docs/terminology/sequence) 中）。
3. 拉伸音频（通过添加 [`playbackRate`](/docs/audio#playbackrate)）。

例如，对于一个 30 FPS 的合成，长度为 60 帧：

1. 一个 [`<Audio>`](/docs/audio) 标签的 [`startFrom`](/docs/audio#startfrom--endat) 值为 45。音频的前 1.5 秒被裁剪掉。
2. [`<Audio>`](/docs/audio) 标签在从 `30` 开始的 [`<Sequence>`](/docs/sequence) 中。音频仅在 1.0 秒时间轴标记处的 1.5 秒音频位置开始播放。
3. [`<Audio>`](/docs/audio) 具有 [`playbackRate`](/docs/audio#playbackrate) 为 `2`。音频加速 2 倍，但起始位置和起始偏移不受影响。
4. 合成为 60 帧长，因此音频必须在第 3.5 秒停止：
   > (comp_duration - offset) \* playback_rate + start_from  
   > (60 - 30) \* 2 + 45 => 帧 105 或第 3.5 秒标记
5. 结果：音频的 1.5 秒至 3.5 秒部分被剪切，并以 2 倍速在 Remotion 时间轴的帧 30 到 59 之间播放。

## 参见

- [导入资产](/docs/assets)
- [音频可视化](/docs/audio-visualization)
- [`<Audio />`](/docs/audio) 标签


